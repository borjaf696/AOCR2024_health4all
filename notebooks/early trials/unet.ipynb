{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your data directories\n",
    "train_images_dir = '../aocr2024/1_Train,Valid_Image/'\n",
    "train_masks_dir = '../aocr2024/1_Train,Valid_Mask/'\n",
    "\n",
    "batch_size = 16\n",
    "n_epoch = 3\n",
    "val_steps = 3\n",
    "\n",
    "# Define a function to load and preprocess NIfTI images\n",
    "def load_nifti_image(file_path):\n",
    "    image = nib.load(file_path).get_fdata()\n",
    "    # Add any necessary preprocessing steps here\n",
    "    return image\n",
    "\n",
    "# Create data generators for training and validation\n",
    "def generate_data_generator(images_dir, masks_dir, subset='training', batch_size=batch_size):\n",
    "    #image_files = [os.path.join(images_dir, file) for file in os.listdir(images_dir)]\n",
    "    #mask_files = [os.path.join(masks_dir, file) for file in os.listdir(masks_dir)]\n",
    "\n",
    "    # Assume the images and masks have the same file names\n",
    "    file_names = [os.path.splitext(file)[0] for file in os.listdir(images_dir)]\n",
    "    file_names.sort()\n",
    "\n",
    "    # Split into training and validation sets\n",
    "    split_index = int(len(file_names) * 0.8)\n",
    "    if subset == 'training':\n",
    "        file_names = file_names[:split_index]\n",
    "    else:\n",
    "        file_names = file_names[split_index:]\n",
    "\n",
    "    while True:\n",
    "        for i in range(0, len(file_names), batch_size):\n",
    "            batch_files = file_names[i:i + batch_size]\n",
    "            batch_images = [load_nifti_image(os.path.join(images_dir, f + '.gz')) for f in batch_files]\n",
    "            batch_masks = [load_nifti_image(os.path.join(masks_dir, f + '.gz')) for f in batch_files]\n",
    "\n",
    "            yield (np.array(batch_images), np.array(batch_masks))\n",
    "\n",
    "# Define the simplified 2D U-Net model\n",
    "def simple_2d_unet_model(input_shape=(512, 512, 90)):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Encoder\n",
    "    conv1 = layers.Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
    "    conv1 = layers.Conv2D(64, 3, activation='relu', padding='same')(conv1)\n",
    "    pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = layers.Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
    "    conv2 = layers.Conv2D(128, 3, activation='relu', padding='same')(conv2)\n",
    "    pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    # Mid-level\n",
    "    conv3 = layers.Conv2D(256, 3, activation='relu', padding='same')(pool2)\n",
    "\n",
    "    # Decoder\n",
    "    up1 = layers.UpSampling2D(size=(2, 2))(conv3)\n",
    "    concat1 = layers.concatenate([up1, conv2], axis=-1)\n",
    "    conv4 = layers.Conv2D(128, 3, activation='relu', padding='same')(concat1)\n",
    "\n",
    "    up2 = layers.UpSampling2D(size=(2, 2))(conv4)\n",
    "    concat2 = layers.concatenate([up2, conv1], axis=-1)\n",
    "    conv5 = layers.Conv2D(64, 3, activation='relu', padding='same')(concat2)\n",
    "\n",
    "    # Output layer\n",
    "    outputs = layers.Conv2D(1, 1, activation='sigmoid')(conv5)\n",
    "\n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    return model\n",
    "\n",
    "# Instantiate the 2D U-Net model\n",
    "simple_2d_model = simple_2d_unet_model()\n",
    "\n",
    "# Compile the model\n",
    "simple_2d_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Set the number of steps per epoch based on your batch size and the number of training samples\n",
    "num_train_samples = len(os.listdir(train_images_dir))\n",
    "steps_per_epoch = num_train_samples // batch_size\n",
    "\n",
    "# Create data generators\n",
    "train_data_generator = generate_data_generator(train_images_dir, train_masks_dir, subset='training', batch_size=batch_size)\n",
    "validation_data_generator = generate_data_generator(train_images_dir, train_masks_dir, subset='validation', batch_size=batch_size)\n",
    "\n",
    "# Train the model\n",
    "simple_2d_model.fit(\n",
    "    train_data_generator, \n",
    "    steps_per_epoch=steps_per_epoch, \n",
    "    epochs=n_epoch, \n",
    "    validation_data=validation_data_generator, \n",
    "    validation_steps=val_steps\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps to try: \n",
    "- Reduce to 1 epoch\n",
    "- Fit on test data\n",
    "- Get results formatted as expected \n",
    "- Submit\n",
    "\n",
    "Then go back and adjust model!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
