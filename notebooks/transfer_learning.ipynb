{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "\n",
    "IMAGES_TO_LOAD = 10\n",
    "\n",
    "def preprocess_nifti_image(img, max_dim = 100):\n",
    "    height, width, depth = img.shape\n",
    "    start = max(0, depth // 2 - max_dim // 2)\n",
    "    end = min(depth, depth // 2 + max_dim // 2)\n",
    "    new_img = np.zeros((height, width, max_dim), dtype=img.dtype)\n",
    "    # Avoid odd dimensions during the redimension\n",
    "    if (end - start) % 2 != 0:\n",
    "        start += 1\n",
    "    new_img[:, :, (max_dim // 2 - (end - start)//2):(max_dim // 2 + (end - start)//2)] = img[:, :, start:end]\n",
    "\n",
    "    return new_img\n",
    "\n",
    "def reshape_input(volume):\n",
    "    # Change from [100, 512, 512, 1] to [T, H, W, C]\n",
    "    reshaped = np.moveaxis(volume, -1, 0)\n",
    "    reshaped = np.expand_dims(reshaped, -1) \n",
    "    return reshaped\n",
    "\n",
    "def load_nii_images(folder, labels_file):\n",
    "    preprocessed_images = []\n",
    "    labels = []\n",
    "    labels_df = pd.read_csv(labels_file)\n",
    "    for i, file_name in enumerate(os.listdir(folder)):\n",
    "        if i >= IMAGES_TO_LOAD:\n",
    "            break\n",
    "        if file_name.endswith('.nii.gz'):\n",
    "            id = file_name.split(\"/\")[-1].split(\".\")[0]\n",
    "            \n",
    "            file_path = os.path.join(folder, file_name)\n",
    "            image_nifti = nib.load(file_path)\n",
    "            image_array = image_nifti.get_fdata()\n",
    "            preprocessed_image = preprocess_nifti_image(image_array)\n",
    "            preprocessed_image_reshaped = reshape_input(preprocessed_image)\n",
    "            preprocessed_images.append(\n",
    "                preprocessed_image_reshaped\n",
    "            )\n",
    "            \n",
    "            labels.append(\n",
    "                int(\n",
    "                    labels_df.loc[\n",
    "                        labels_df.id == id,\n",
    "                        \"label\"\n",
    "                    ].iloc[\n",
    "                        0\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "    images_tensor = torch.tensor(preprocessed_images, dtype = torch.float32)\n",
    "    # Let's repeat the input to adapt it to the 3 required channels\n",
    "    images_tensor = images_tensor.repeat(1, 1, 1, 1, 3) \n",
    "    # Permutate the input to match the dimensions in the model\n",
    "    images_tensor = images_tensor.permute(0, 4, 1, 2, 3)\n",
    "    labels_tensor = torch.tensor(labels, dtype=torch.int64)\n",
    "    return {\n",
    "        \"images\": images_tensor, \n",
    "        \"labels\": labels_tensor\n",
    "    }\n",
    "# Load the images and reshape if necessary\n",
    "dict_images = load_nii_images('../aocr2024/1_Train,Valid_Image/', \"../aocr2024/TrainValid_ground_truth.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "\n",
    "class ModifiedR3D18(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModifiedR3D18, self).__init__()\n",
    "        self.r3d_18 = models.video.r3d_18(pretrained=True)\n",
    "        num_ftrs = self.r3d_18.fc.in_features\n",
    "        self.r3d_18.fc = nn.Sequential(\n",
    "            nn.Linear(num_ftrs, 1), \n",
    "            nn.Sigmoid()            \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.r3d_18(x)\n",
    "\n",
    "model = ModifiedR3D18()\n",
    "model.train()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(dict_images[\"images\"], dict_images[\"labels\"])\n",
    "batch_size = 16\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "for epoch in range(num_epochs):  \n",
    "    for data in dataloader:    \n",
    "        inputs, labels = data    \n",
    "\n",
    "        optimizer.zero_grad()    \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_images[\"images\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
